{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a36e2573",
   "metadata": {},
   "source": [
    "# Explore Data Science Academy Classification Hackathon Student Solution\n",
    "\n",
    "© Explore Data Science Academy\n",
    "\n",
    "\n",
    "# Overview\n",
    "South Africa is a multicultural society that is characterised by its rich linguistic diversity. Language is an indispensable tool that can be used to deepen democracy and also contribute to the social, cultural, intellectual, economic and political life of the South African society.\n",
    "\n",
    "The country is multilingual with 11 official languages, each of which is guaranteed equal status. Most South Africans are multilingual and able to speak at least two or more of the official languages.\n",
    "From South African Government\n",
    "\n",
    "<img src=\"C:\\Users\\F5481295\\OneDrive - FRG\\Downloads\\06 - Advanced Classification\\LANGUAGE IDENTIFICATION CLASSIFICATION HACKATHON\" width=400 height=400 />\n",
    "\n",
    "With such a multilingual population, it is only obvious that our systems and devices also communicate in multi-languages.\n",
    "\n",
    "In this challenge, we will take text which is in any of South Africa's 11 Official languages and identify which language the text is in. This is an example of NLP's Language Identification, the task of determining the natural language that a piece of text is written in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2b95fd",
   "metadata": {},
   "source": [
    "<a id=\"cont\"></a>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "<a href=#one>1. Importing Packages</a>\n",
    "\n",
    "<a href=#two>2. Loading Data</a>\n",
    "\n",
    "<a href=#three>3. Exploratory Data Analysis (EDA)</a>\n",
    "\n",
    "<a href=#four>4. Data Processing and Engineering</a>\n",
    "\n",
    "<a href=#five>5. Model Development</a>\n",
    "\n",
    "<a href=#six>6. Model Training and Testing</a>\n",
    "\n",
    "<a href=#seven>7. Model Performance</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e47696",
   "metadata": {},
   "source": [
    " <a id=\"one\"></a>\n",
    "## 1. Importing Packages\n",
    "<a href=#cont>Back to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc6f6c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for loading data, data manipulation and data visulisation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import re # Regular expression python module\n",
    "import string\n",
    "\n",
    "# nltk for preprocessing of text data\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Labraries for model builduing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0998487",
   "metadata": {},
   "source": [
    "<a id=\"two\"></a>\n",
    "## 2. Loading the Data\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fec5e384",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_set.csv')\n",
    "test = pd.read_csv('test_set.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656a5278",
   "metadata": {},
   "source": [
    "<a id=\"three\"></a>\n",
    "## 3. Exploratory Data Analysis (EDA)\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75fc681e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nso</td>\n",
       "      <td>dinyakišišo tše tša go dirwa gabedi ka ngwaga ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tsn</td>\n",
       "      <td>kgetse nngwe le nngwe e e sa faposiwang mo tsh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ven</td>\n",
       "      <td>mbadelo dze dza laelwa dzi do kwama mahatulele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nso</td>\n",
       "      <td>maloko a dikhuduthamaga a ikarabela mongwe le ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tsn</td>\n",
       "      <td>fa le dirisiwa lebone le tshwanetse go bontsha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang_id                                               text\n",
       "0     xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...\n",
       "1     xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...\n",
       "2     eng  the province of kwazulu-natal department of tr...\n",
       "3     nso  o netefatša gore o ba file dilo ka moka tše le...\n",
       "4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana...\n",
       "5     nso  dinyakišišo tše tša go dirwa gabedi ka ngwaga ...\n",
       "6     tsn  kgetse nngwe le nngwe e e sa faposiwang mo tsh...\n",
       "7     ven  mbadelo dze dza laelwa dzi do kwama mahatulele...\n",
       "8     nso  maloko a dikhuduthamaga a ikarabela mongwe le ...\n",
       "9     tsn  fa le dirisiwa lebone le tshwanetse go bontsha..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10) # To view the first 10 rows of the train set data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1723be1",
   "metadata": {},
   "source": [
    "The train dataset has 2 columns,which are `lang_id` and `text`. The `lang_id` column is the target variable and the `text` column contains the text that we will clean and preprocess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04d47102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5672</th>\n",
       "      <td>5673</td>\n",
       "      <td>Die raad kan van tyd tot tyd en in ooreenstemm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5673</th>\n",
       "      <td>5674</td>\n",
       "      <td>halutshedzo ya ' tshiimo tsha u vha na vhudzim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5674</th>\n",
       "      <td>5675</td>\n",
       "      <td>botlalo tšeo di hlokegago o mongwe le o mongwe.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5675</th>\n",
       "      <td>5676</td>\n",
       "      <td>Muanewa-muhali. Mafhungo o he a lungano a kwam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5676</th>\n",
       "      <td>5677</td>\n",
       "      <td>Afitafiti go tšwa go leloko go netefatša tlhok...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5677</th>\n",
       "      <td>5678</td>\n",
       "      <td>You mark your ballot in private.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5678</th>\n",
       "      <td>5679</td>\n",
       "      <td>Ge o ka kgetha ka bowena go se šomiše Mofani k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5679</th>\n",
       "      <td>5680</td>\n",
       "      <td>E Ka kopo etsa kgetho ya hao ka hloko, hobane ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5680</th>\n",
       "      <td>5681</td>\n",
       "      <td>TB ke bokudi ba PMB, mme Morero o tla lefella ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5681</th>\n",
       "      <td>5682</td>\n",
       "      <td>Vakatjhela iwebhusayidi yethu ku-www.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                               text\n",
       "5672   5673  Die raad kan van tyd tot tyd en in ooreenstemm...\n",
       "5673   5674  halutshedzo ya ' tshiimo tsha u vha na vhudzim...\n",
       "5674   5675    botlalo tšeo di hlokegago o mongwe le o mongwe.\n",
       "5675   5676  Muanewa-muhali. Mafhungo o he a lungano a kwam...\n",
       "5676   5677  Afitafiti go tšwa go leloko go netefatša tlhok...\n",
       "5677   5678                   You mark your ballot in private.\n",
       "5678   5679  Ge o ka kgetha ka bowena go se šomiše Mofani k...\n",
       "5679   5680  E Ka kopo etsa kgetho ya hao ka hloko, hobane ...\n",
       "5680   5681  TB ke bokudi ba PMB, mme Morero o tla lefella ...\n",
       "5681   5682              Vakatjhela iwebhusayidi yethu ku-www."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.tail(10) # To view the last 10 rows of the train set data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804265f1",
   "metadata": {},
   "source": [
    "The test dataset  doesn't have the `lang_id` column because we want to build a Machine Learning model(s) that can classify a text into one of South Africa's 11 official languages, and we will use this data to test our model(s). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e0db20c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Understand the number of features and data points in the train dataset\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46f2f5e",
   "metadata": {},
   "source": [
    "So we've got 33,000 samples (text), each with 2 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3061672f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5682, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Understand the number of features and data points in the test dataset\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80144a9",
   "metadata": {},
   "source": [
    "For the test dataset we've got 5,682 samples (text), each with 2 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0824cc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33000 entries, 0 to 32999\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   lang_id  33000 non-null  object\n",
      " 1   text     33000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 515.8+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0765b4",
   "metadata": {},
   "source": [
    "As we can see both the `lang_id` and `text` features have object data type. Later we will have to convert the `text` column from object data type into numeric data type since computers can't understand natural language. It also seems like the columns have no null values, but we can check just to be sure,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c0a8ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lang_id    0\n",
       "text       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f103a10c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index    0\n",
       "text     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3b41af",
   "metadata": {},
   "source": [
    "Therefore, we can see that both the train set and test set data have no null values. Now let's look at the values that we have on the `lang_id` column and how are they distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "452e616b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['xho', 'eng', 'nso', 'ven', 'tsn', 'nbl', 'zul', 'ssw', 'tso',\n",
       "       'sot', 'afr'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['lang_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "331f347d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xho    3000\n",
       "eng    3000\n",
       "nso    3000\n",
       "ven    3000\n",
       "tsn    3000\n",
       "nbl    3000\n",
       "zul    3000\n",
       "ssw    3000\n",
       "tso    3000\n",
       "sot    3000\n",
       "afr    3000\n",
       "Name: lang_id, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"lang_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36436d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcMAAAFGCAYAAAAW+/S1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAca0lEQVR4nO3dfdhldV3v8fdHQER5EA4D0Qw6qFQCKsaAJGYqnpj0dMBSG08pFTkexMwsCzrHxK7myjpJig8oJk+lcsg0EDRDwgc6PA2I8nwxgeLIKJNWYCbK+D1/rHXDdubmnhvn3nvtmd/7dV372mv99lp7fQdm9mev3/qt305VIUlSyx4xdAGSJA3NMJQkNc8wlCQ1zzCUJDXPMJQkNW/7oQsYlz333LOWLl06dBmSpClxzTXX/EtVLZrttW02DJcuXcrq1auHLkOSNCWSfPmhXrObVJLUPMNQktQ8w1CS1DzDUJLUPMNQktQ8w1CS1DzDUJLUPMNQktS8sYVhkkcluSrJF5LcmOTNffseSS5Oclv/vPvIPiclWZPk1iRHjbQfkuT6/rVTk2RcdUuS2jPOM8P7gOdV1dOAg4HlSQ4HTgQuqar9gUv6dZIcAKwADgSWA+9Osl3/XqcBK4H9+8fyMdYtSWrM2MKwOt/qV3foHwUcDZzdt58NHNMvHw2cW1X3VdUdwBrgsCT7ALtW1eVVVcA5I/tIkrTFxjo3aX9mdw3wJOBdVXVlkr2rah1AVa1Lsle/+WLgipHd1/Zt3+uXN26f7Xgr6c4gedzjHrfZ+paeeNHD+vPM5ktveeEWvwcsTC0wXfVMUy0wXfVMUy0wXfVMUy0wXfVMUy0wXfVsaS1jHUBTVRuq6mBgCd1Z3kFzbD7bdcCao322451eVcuqatmiRbNOTC5J0iYmMpq0qv4N+DTdtb6v912f9M9395utBfYd2W0JcFffvmSWdkmSFsQ4R5MuSvLYfnkn4PnALcAFwLH9ZscC5/fLFwArkuyYZD+6gTJX9V2q9yY5vB9F+oqRfSRJ2mLjvGa4D3B2f93wEcB5VXVhksuB85IcB9wJvASgqm5Mch5wE3A/cEJVbejf63jgLGAn4BP9Q5KkBTG2MKyqLwJPn6X9G8CRD7HPKmDVLO2rgbmuN0qS9ENzBhpJUvMMQ0lS8wxDSVLzDENJUvMMQ0lS8wxDSVLzDENJUvMMQ0lS8wxDSVLzDENJUvMMQ0lS8wxDSVLzDENJUvMMQ0lS8wxDSVLzDENJUvMMQ0lS8wxDSVLzDENJUvMMQ0lS8wxDSVLzDENJUvMMQ0lS8wxDSVLzDENJUvMMQ0lS8wxDSVLzDENJUvMMQ0lS8wxDSVLzDENJUvMMQ0lS8wxDSVLzDENJUvPGFoZJ9k1yaZKbk9yY5Lf69pOTfDXJdf3jBSP7nJRkTZJbkxw10n5Ikuv7105NknHVLUlqz/ZjfO/7gd+pqmuT7AJck+Ti/rW/qKo/H904yQHACuBA4EeBTyX5saraAJwGrASuAD4OLAc+McbaJUkNGduZYVWtq6pr++V7gZuBxXPscjRwblXdV1V3AGuAw5LsA+xaVZdXVQHnAMeMq25JUnsmcs0wyVLg6cCVfdNrknwxyRlJdu/bFgNfGdltbd+2uF/euH2246xMsjrJ6vXr1y/kH0GStA0bexgm2Rn4W+B1VXUPXZfnE4GDgXXAW2c2nWX3mqN908aq06tqWVUtW7Ro0ZaWLklqxFjDMMkOdEH4gar6CEBVfb2qNlTV94H3AYf1m68F9h3ZfQlwV9++ZJZ2SZIWxDhHkwZ4P3BzVZ0y0r7PyGYvAm7oly8AViTZMcl+wP7AVVW1Drg3yeH9e74COH9cdUuS2jPO0aRHAC8Hrk9yXd/2B8DLkhxM19X5JeBVAFV1Y5LzgJvoRqKe0I8kBTgeOAvYiW4UqSNJJUkLZmxhWFWXMfv1vo/Psc8qYNUs7auBgxauOkmSHuQMNJKk5hmGkqTmGYaSpOYZhpKk5hmGkqTmGYaSpOYZhpKk5hmGkqTmGYaSpOYZhpKk5hmGkqTmGYaSpOYZhpKk5hmGkqTmGYaSpOYZhpKk5hmGkqTmGYaSpOYZhpKk5hmGkqTmGYaSpOYZhpKk5hmGkqTmGYaSpOYZhpKk5hmGkqTmGYaSpOYZhpKk5hmGkqTmGYaSpOYZhpKk5hmGkqTmGYaSpOYZhpKk5o0tDJPsm+TSJDcnuTHJb/XteyS5OMlt/fPuI/uclGRNkluTHDXSfkiS6/vXTk2ScdUtSWrPOM8M7wd+p6qeDBwOnJDkAOBE4JKq2h+4pF+nf20FcCCwHHh3ku369zoNWAns3z+Wj7FuSVJjxhaGVbWuqq7tl+8FbgYWA0cDZ/ebnQ0c0y8fDZxbVfdV1R3AGuCwJPsAu1bV5VVVwDkj+0iStMUmcs0wyVLg6cCVwN5VtQ66wAT26jdbDHxlZLe1fdvifnnj9tmOszLJ6iSr169fv6B/BknStmvsYZhkZ+BvgddV1T1zbTpLW83Rvmlj1elVtayqli1atOjhFytJatJYwzDJDnRB+IGq+kjf/PW+65P++e6+fS2w78juS4C7+vYls7RLkrQgxjmaNMD7gZur6pSRly4Aju2XjwXOH2lfkWTHJPvRDZS5qu9KvTfJ4f17vmJkH0mSttj2Y3zvI4CXA9cnua5v+wPgLcB5SY4D7gReAlBVNyY5D7iJbiTqCVW1od/veOAsYCfgE/1DkqQFMbYwrKrLmP16H8CRD7HPKmDVLO2rgYMWrjpJkh7kDDSSpOYZhpKk5hmGkqTmGYaSpOYZhpKk5hmGkqTmGYaSpOYZhpKk5hmGkqTmGYaSpOYZhpKk5hmGkqTmGYaSpOYZhpKk5hmGkqTmGYaSpOY97DBMsnuSp46jGEmShjCvMEzy6SS7JtkD+AJwZpJTxluaJEmTMd8zw92q6h7gF4Azq+oQ4PnjK0uSpMmZbxhun2Qf4KXAhWOsR5KkiZtvGL4Z+CSwpqquTvIE4LbxlSVJ0uRsP8/t1lXVA4Nmqup2rxlKkrYV8z0zfMc82yRJ2urMeWaY5KeAZwKLkrx+5KVdge3GWZgkSZOyuW7SRwI799vtMtJ+D/DicRUlSdIkzRmGVfUZ4DNJzqqqL0+oJkmSJmq+A2h2THI6sHR0n6p63jiKkiRpkuYbhn8DvAf4S2DD+MqRJGny5huG91fVaWOtRJKkgcz31oqPJXl1kn2S7DHzGGtlkiRNyHzPDI/tn98w0lbAExa2HEmSJm9eYVhV+427EEmShjKvMEzyitnaq+qchS1HkqTJm2836aEjy48CjgSuBQxDSdJWb77dpL85up5kN+CvxlKRJEkTNt/RpBv7NrD/XBskOSPJ3UluGGk7OclXk1zXP14w8tpJSdYkuTXJUSPthyS5vn/t1CT5IWuWJGlW871m+DG60aPQTdD9ZOC8zex2FvBONu1K/Yuq+vON3v8AYAVwIPCjwKeS/FhVbQBOA1YCVwAfB5YDn5hP3ZIkzcd8rxmOhtf9wJerau1cO1TVZ5Msnef7Hw2cW1X3AXckWQMcluRLwK5VdTlAknOAYzAMJUkLaF7dpP2E3bfQ/XLF7sB3t+CYr0nyxb4bdfe+bTHwlZFt1vZti/vljdtnlWRlktVJVq9fv34LSpQktWReYZjkpcBVwEuAlwJXJvlhfsLpNOCJwMHAOuCtM4eYZduao31WVXV6VS2rqmWLFi36IcqTJLVovt2k/ws4tKruBkiyCPgU8OGHc7Cq+vrMcpL3ARf2q2uBfUc2XQLc1bcvmaVdkqQFM9/RpI+YCcLeNx7Gvg9Iss/I6ouAmZGmFwArkuyYZD+6kapXVdU64N4kh/ejSF8BnP9wjytJ0lzme2b490k+CXyoX/8lupGdDynJh4DnAHsmWQu8CXhOkoPpujq/BLwKoKpuTHIecBPdAJ0T+pGkAMfTjUzdiW7gjINnJEkLas4wTPIkYO+qekOSXwCeRXcd73LgA3PtW1Uvm6X5/XNsvwpYNUv7auCguY4lSdKW2FxX59uAewGq6iNV9fqq+m26s8K3jbc0SZImY3NhuLSqvrhxY3+2tnQsFUmSNGGbC8NHzfHaTgtZiCRJQ9lcGF6d5JUbNyY5DrhmPCVJkjRZmxtN+jrgo0l+mQfDbxnwSLpbIyRJ2urNGYb9TfLPTPJcHhzReVFV/ePYK5MkaULm+3uGlwKXjrkWSZIG8cP+nqEkSdsMw1CS1DzDUJLUPMNQktQ8w1CS1DzDUJLUPMNQktQ8w1CS1DzDUJLUPMNQktQ8w1CS1DzDUJLUPMNQktQ8w1CS1DzDUJLUPMNQktQ8w1CS1DzDUJLUPMNQktQ8w1CS1DzDUJLUPMNQktQ8w1CS1DzDUJLUPMNQktQ8w1CS1DzDUJLUvLGFYZIzktyd5IaRtj2SXJzktv5595HXTkqyJsmtSY4aaT8kyfX9a6cmybhqliS1aZxnhmcByzdqOxG4pKr2By7p10lyALACOLDf591Jtuv3OQ1YCezfPzZ+T0mStsjYwrCqPgt8c6Pmo4Gz++WzgWNG2s+tqvuq6g5gDXBYkn2AXavq8qoq4JyRfSRJWhCTvma4d1WtA+if9+rbFwNfGdlubd+2uF/euH1WSVYmWZ1k9fr16xe0cEnStmtaBtDMdh2w5mifVVWdXlXLqmrZokWLFqw4SdK2bdJh+PW+65P++e6+fS2w78h2S4C7+vYls7RLkrRgJh2GFwDH9svHAuePtK9IsmOS/egGylzVd6Xem+TwfhTpK0b2kSRpQWw/rjdO8iHgOcCeSdYCbwLeApyX5DjgTuAlAFV1Y5LzgJuA+4ETqmpD/1bH041M3Qn4RP+QJGnBjC0Mq+plD/HSkQ+x/Spg1Sztq4GDFrA0SZJ+wLQMoJEkaTCGoSSpeYahJKl5hqEkqXmGoSSpeYahJKl5hqEkqXmGoSSpeYahJKl5hqEkqXmGoSSpeYahJKl5hqEkqXmGoSSpeYahJKl5hqEkqXmGoSSpeYahJKl5hqEkqXmGoSSpeYahJKl5hqEkqXmGoSSpeYahJKl5hqEkqXmGoSSpeYahJKl5hqEkqXmGoSSpeYahJKl5hqEkqXmGoSSpeYahJKl5hqEkqXmDhGGSLyW5Psl1SVb3bXskuTjJbf3z7iPbn5RkTZJbkxw1RM2SpG3XkGeGz62qg6tqWb9+InBJVe0PXNKvk+QAYAVwILAceHeS7YYoWJK0bZqmbtKjgbP75bOBY0baz62q+6rqDmANcNjky5MkbauGCsMC/iHJNUlW9m17V9U6gP55r759MfCVkX3X9m2bSLIyyeokq9evXz+m0iVJ25rtBzruEVV1V5K9gIuT3DLHtpmlrWbbsKpOB04HWLZs2azbSJK0sUHODKvqrv75buCjdN2eX0+yD0D/fHe/+Vpg35HdlwB3Ta5aSdK2buJhmOQxSXaZWQZ+FrgBuAA4tt/sWOD8fvkCYEWSHZPsB+wPXDXZqiVJ27Ihukn3Bj6aZOb4H6yqv09yNXBekuOAO4GXAFTVjUnOA24C7gdOqKoNA9QtSdpGTTwMq+p24GmztH8DOPIh9lkFrBpzaZKkRk3TrRWSJA3CMJQkNc8wlCQ1zzCUJDXPMJQkNc8wlCQ1zzCUJDXPMJQkNc8wlCQ1zzCUJDXPMJQkNc8wlCQ1zzCUJDXPMJQkNc8wlCQ1zzCUJDXPMJQkNc8wlCQ1zzCUJDXPMJQkNc8wlCQ1zzCUJDXPMJQkNc8wlCQ1zzCUJDXPMJQkNc8wlCQ1zzCUJDXPMJQkNc8wlCQ1zzCUJDXPMJQkNc8wlCQ1zzCUJDVvqwnDJMuT3JpkTZITh65HkrTt2CrCMMl2wLuAnwMOAF6W5IBhq5IkbSu2ijAEDgPWVNXtVfVd4Fzg6IFrkiRtI1JVQ9ewWUleDCyvqt/o118OPKOqXrPRdiuBlf3qjwO3buGh9wT+ZQvfYyFNUz3TVAtMVz3TVAtYz1ymqRaYrnqmqRZYmHoeX1WLZnth+y1840nJLG2bpHhVnQ6cvmAHTVZX1bKFer8tNU31TFMtMF31TFMtYD1zmaZaYLrqmaZaYPz1bC3dpGuBfUfWlwB3DVSLJGkbs7WE4dXA/kn2S/JIYAVwwcA1SZK2EVtFN2lV3Z/kNcAnge2AM6rqxgkcesG6XBfINNUzTbXAdNUzTbWA9cxlmmqB6apnmmqBMdezVQygkSRpnLaWblJJksbGMJQkNc8wlCQ1zzCUJDVvqxhNOklJdgCOB57dN30GeE9VfW+4qqZLkl2AqqpvDVjDjsAvAksZ+XtcVX80VE36QUleP9frVXXKpGoZleQJVXX7EMeeTZL/zsjnTVV9bMBaLqmqIzfXNoE6tgM+WVXPn9QxDcNNnQbsALy7X3953/Ybky4kyb1sOtPOvwOrgd+Z9D/oJE8BzgH26FazHji2qm6YZB298+n+W1wD3DfA8X9AkkXAK9k0nH99wnW8g1lmZ5pRVa+dYDm7TPBYD8dZSRbT3b/8WeBzVXX9EIUk+RO6uZc/0De9Nskzq+qkCdfxKODRwJ5JdufBWb92BX50krUAVNWGJN9OsltV/fskjmkYburQqnrayPo/JvnCQLWcQjfTzgfp/nKuAH6Ebs7VM4DnTLie9wKvr6pLAZI8h+7en2dOuA6AJVW1fIDjPpTzgc8BnwI2DFjH6gGP/QOq6s1D1zCbqnp2P3nHoXT/hi5KsnNV7TFAOS8EDq6q7wMkORv4PDDRMAReBbyOLviuHWm/h+4Xg4bwHeD6JBcD/zHTOK4vdIbhpjYkeWJV/TN0XSoM9+G2vKqeMbJ+epIrquqPkvzBAPU8ZiYIAarq00keM0AdAP8vyVOG+kY/i0dX1e8PXURVnT26nmTXrrnuHagkkpzJ7HMJT/SseUaSZwE/3T8eC1xI90VmKI8Fvtkv7zZEAVX1duDtSX6zqt4xRA2zuKh/TIRhuKk3AJcmuZ3ubOzxwK8NVMv3k7wU+HC//uKR14aYLeH2JG8E/qpf/xXgjgHqAHgW8KtJ7qDrJg3dh/5TB6rnwiQvqKqPD3T8H5BkGXAmXVdlkvwb8OtVdc0A5Vw4svwo4EUMO7fwZ+jOoP8E+Hj/s3BD+RPg80kupfs7/Gwmf1Y46r1JXsuD1zA/Dbx3kmMmRq5RHjDJL5jOQDOLfnDGj9P95bylqga5JtWflb4d+Cm68LsC+G3gq8AhVXXZhOvZHXgzXRCF7kPlzVX1r5Oso6/l8bO1V9WXJ10LPHB99zF0wfw9HgznXQeq54vACVX1uX79WcC7B/yy8IAkjwA+VVXPG+j4jwWOoPvAPxT4PnB5Vb1xoHr26esIcGVVfW2IOvpa/pJuzMRMD8PLgQ0zP583oRpuohvE+B7gf7DRrxZV1bWz7bfFxzUMN5XkmWw6EOKcwQqaQv1or8dU1T0D1vAsYP+qOrMfwLJzVQ11pjpVkvxTVR2xubYhJPlx4KKqetKANTwZ+Bm6rtJnAndW1c8MUMcRwHVV9R9JfgX4SeDtA36p+8JGYyZmbRtzDS8GjqP70r3xNfAa15cou0k3kuSvgCcC1/HgtcKiG0U56VqmYoTiSD0fBP4n3X+Xa4DdkpxSVf9ngFreBCyjO4M/k+7b7F/TfeOfuIf4UHtbVd054Tp+sl+8Ksl7gQ/R/f39Jbour4kbGRWd/vlrwO8NUUtfzz/TDUL7HN3Zx68N2FV6GvC0JE+ju0RzBt1nzcSDuTf4mImq+jDw4f6SzDuBH6PrXh/rmZthuKlldH3V03DKPC0jFGccUFX3JPll4OPA79OF4sTDkO6609PpR75V1V39/Y9DGf1Q+z3g/XTXVif9ofbWjdb/sH+eCaIhXA28taoeGAyR5HTgIwPVs//M6M0psKGqKsnRwKlV9f4kxw5Yz+/y4JgJ6L6IDzVm4mt0t74soTs5ORy4HPDMcEJuoLt9Yd3QhTAlIxRH7NBPSnAM8M6q+l6SzewyNt/tP0QKYMBRrTNGP9TePtSHWlU9Fx64b2zjSQmGCsOlwO8lOWRkUoQhf0H9LUn+GPhP4O+BpwGvq6q/HqCWe5KcRDcY7dn95YchP5f/C3AQ3f+zo+m6kCdyn98sXkt3LfWKqnpukp+gG7MwFk7H1kvysSQXAHsCNyX5ZJILRtqHcGGSFwx07Nm8F/gS3UCRz/aDWIb6h3Je3w342CSvpDt7ft9AtcAPfqhdNAUfan8H/DzdYJ5vjTyG8G/AkcCP9P+eBrl9YMTP9te6/xuwlq4b7g0D1XIr3aCr4/qBM4vp/n0N5Y39f5tdgf9K14182kC1fKeqvgPdoMaquoXusshYeGb4oD/vnw8ETt7otaFOf34LOCnJd5mCEYp0YfgNum+Nb6T7MvXpgWr5Pl0X8j10H2Z/WFUXD1QLbPShluRxDPuhNk2TEqSq7gdeneRXgcuA3QesZ4f++QXAh6rqmwP2cCyrqpUzK1V1Z5JvD1UMD16OeSHdNJTnJzl5oFrW9iN//w64OMm/MsZbcgzDXlV9BiDJu+iu9fwZ3UXbP6Pr0vmpAcraDfhlYL/+RvvHAfsMUMeM8+m+5V9LNzsEDNf1tgvdiLNvAucCXxyojhnT9qE2TZMSvGdmoarOSnI9cMKA9VyQ5Ba6btJX9wPVvrOZfRZUkuOBVwNP6G+DmbEL8E+TrGUjX+17XJ4P/Gl/m9kgPYhV9aJ+8eT+Pszd6Lq1x8JbKzbSX3v6U+AQur+YHwD+dIgL7klOozsDel5VPbm/z+8fqurQSdfS13NDVR00xLEfSpKn0o2U/EVg7SQn9u2P/8CHGvDPIy/tAvxTVf3KJOsZqesm4El0kyJMw6QEUyPJS4Ar6e7XPYnufsM3V9XEQqjvKt6d7qb7E0deureqvjn7XuOX5NHAcuD6qrqtvwfyKVX1D0PVNCmeGW7qe3TfGHeiOzO8Y8CRZ8+oqp9M8nmAqvrXdHMqDmWazjZm3E036uwbwF4DHP+DwCeYsg814OcGPPa0e2NVPbW/T/UoukskpwDPmHu3hdNPPv3vwMsmdcz5qKpvMzLKt6rWMR2DCcfOMNzU1XTdgYfSjax6b5IXV9WL595tLL7XD8SYGTG5iO5McShTMwVaf0b2S8AiuunqXllVN026jin+UBvkpu2txOh1sdMGvi6mKWEYbuq4qpqZ9eBrwNFJXj5QLacCHwX2SrKKbm7S/z1QLTBdZxuPpxsOf93QhWirMzXXxTQ9vGY45fp7a46kOwu7pKpuHrgkaavW8nUxPTTDUJLUPLsGJEnNMwwlSc0zDCVJzTMMpSmVZOJziSb5oySbTFyQ5DlJLpxtH2lb4K0Vkh5QVX+4+a2kbY9nhtJWJMnPJ7kyyeeTfCrJ3n37yUnOSPLpJLcnee3IPm9MckuSi5N8KMnvzvH+Z/W/NE6S5f1+lwG/MPY/nDQgw1DaulwGHF5VT6eboHz0F+N/gm56scOANyXZIckyunlbn04XaPP6HcH+9xDfR/czUD9N9xuf0jbLblJp67IE+L/9jeKPpJuIe8ZFVXUfcF+Su4G96abQO7+q/hO63+2c53F+gm5e3tv6/f4aWDn3LtLWyzNDaevyDuCdVfUU4FV0k8nPuG9keQPdl90t+aE+Z+RQMwxDaeuyG91PDwEcO4/tLwN+PsmjkuxMNzn1fNwC7Jfkif36VE1ELi00u0ml6fXoJGtH1k8BTgb+JslXgSuA/eZ6g6q6OskFwBeALwOr6X5lY05V9Z0kK4GLkvwLXahO1W9ZSgvJuUmlbVySnavqW/0E1Z8FVlbVtUPXJU0Tzwylbd/pSQ6gu754tkEobcozQ6lBSd4FHLFR89ur6swh6pGGZhhKkprnaFJJUvMMQ0lS8wxDSVLzDENJUvP+P+GaRjTCTOqFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train['lang_id'].value_counts().plot(figsize=(7,5),kind='bar')\n",
    "plt.xlabel('Lang_id')\n",
    "plt.ylabel('Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9750ee",
   "metadata": {},
   "source": [
    "As we can see on the bar graph above, the language IDs have the same number of value counts. This means we are dealing with balanced data, which is the type of data we ideally want to work with to get better working models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2372a585",
   "metadata": {},
   "source": [
    "<a id=\"four\"></a>\n",
    "## 4. Data Processing and Engineering\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5322aab5",
   "metadata": {},
   "source": [
    "In this section we will conduct some basic steps of text preprocessing in order to transfer text from human language to machine readable format for further processing. We are going to create a function called `cleaning`, which will Pre-process the `text` column. The function will:\n",
    "* make every letter lower case\n",
    "* remove punctuation\n",
    "* remove numbers\n",
    "* remove whitespaces\n",
    "* replace new line with space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a9b8b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(text):\n",
    "    text = text.lower()\n",
    "    text = ''.join([x for x in text if x not in string.punctuation])\n",
    "    text = re.sub(r'[0-9]+', '', text)\n",
    "    text = re.sub(\"\\n\",\" \",text)\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e03bb4",
   "metadata": {},
   "source": [
    "Next, we will apply the cleaning function on both the train and test dataset to clean the `text` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9f9d1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['clean_text'] = train['text'].apply(cleaning)\n",
    "test['clean_text'] = test['text'].apply(cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17c3c50d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "      <td>umgaqosiseko wenza amalungiselelo kumaziko axh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "      <td>idha iya kuba nobulumko bokubeka umsebenzi nap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "      <td>the province of kwazulunatal department of tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang_id                                               text  \\\n",
       "0     xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...   \n",
       "1     xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...   \n",
       "2     eng  the province of kwazulu-natal department of tr...   \n",
       "3     nso  o netefatša gore o ba file dilo ka moka tše le...   \n",
       "4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  umgaqosiseko wenza amalungiselelo kumaziko axh...  \n",
       "1  idha iya kuba nobulumko bokubeka umsebenzi nap...  \n",
       "2  the province of kwazulunatal department of tra...  \n",
       "3  o netefatša gore o ba file dilo ka moka tše le...  \n",
       "4  khomishini ya ndinganyiso ya mbeu yo ewa maana...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head() # looking at the train dataset after cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8ef6acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mmasepala, fa maemo a a kgethegileng a letlele...</td>\n",
       "      <td>mmasepala fa maemo a a kgethegileng a letlelel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Uzakwaziswa ngokufaneleko nakungafuneka eminye...</td>\n",
       "      <td>uzakwaziswa ngokufaneleko nakungafuneka eminye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tshivhumbeo tshi fana na ngano dza vhathu.</td>\n",
       "      <td>tshivhumbeo tshi fana na ngano dza vhathu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Kube inja nelikati betingevakala kutsi titsini...</td>\n",
       "      <td>kube inja nelikati betingevakala kutsi titsini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Winste op buitelandse valuta.</td>\n",
       "      <td>winste op buitelandse valuta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text  \\\n",
       "0      1  Mmasepala, fa maemo a a kgethegileng a letlele...   \n",
       "1      2  Uzakwaziswa ngokufaneleko nakungafuneka eminye...   \n",
       "2      3         Tshivhumbeo tshi fana na ngano dza vhathu.   \n",
       "3      4  Kube inja nelikati betingevakala kutsi titsini...   \n",
       "4      5                      Winste op buitelandse valuta.   \n",
       "\n",
       "                                          clean_text  \n",
       "0  mmasepala fa maemo a a kgethegileng a letlelel...  \n",
       "1  uzakwaziswa ngokufaneleko nakungafuneka eminye...  \n",
       "2          tshivhumbeo tshi fana na ngano dza vhathu  \n",
       "3  kube inja nelikati betingevakala kutsi titsini...  \n",
       "4                       winste op buitelandse valuta  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head() # looking at the test datasetafter cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09fe43a",
   "metadata": {},
   "source": [
    "After cleaning the `text` column, we will convert it from object data type to numeric data type using the **Tfidf Vectorizer**, so that we can be able to use it in the modelling section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbe33f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the feature and the label\n",
    "X = train['clean_text']\n",
    "y = train['lang_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4955260e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(ngram_range=(1,2), min_df=2) # Defining the vectorizer\n",
    "X_vect = vect.fit_transform(X) # Vectorizing the train dataset feature\n",
    "test_vect = vect.transform(test['clean_text']) # Vectorizing the test dataset feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f099f1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Train set size  (33000, 206620)\n",
      "The Test set size  (5682, 206620)\n"
     ]
    }
   ],
   "source": [
    "print (\"The Train set size \", X_vect.shape)\n",
    "print (\"The Test set size \", test_vect.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0640109e",
   "metadata": {},
   "source": [
    "<a id=\"five\"></a>\n",
    "## 5. Model development and Training\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0820dd59",
   "metadata": {},
   "source": [
    "Before we can begin with building our models we have to split the train data into **train** and **test** set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9212a1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_vect, y, test_size=0.2, random_state=46)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a0f6ec",
   "metadata": {},
   "source": [
    "After splitting the train dataset, we can proceed with training our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b4c83d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an instance of each model\n",
    "log_r = LogisticRegression()\n",
    "forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "svc = SVC(kernel='linear')\n",
    "naive_bayes = MultinomialNB()\n",
    "\n",
    "# fitting each model\n",
    "log_r.fit(X_train, y_train)\n",
    "forest.fit(X_train, y_train)\n",
    "svc.fit(X_train, y_train)\n",
    "naive_bayes.fit(X_train, y_train)\n",
    "\n",
    "# making predictions using each model\n",
    "pred_log = log_r.predict(X_test)\n",
    "pred_forest = forest.predict(X_test)\n",
    "svc_pred = svc.predict(X_test)\n",
    "pred_bayes = naive_bayes.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5253fd0",
   "metadata": {},
   "source": [
    "<a id=\"seven\"></a>\n",
    "## 7. Model Performance\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f1dc09",
   "metadata": {},
   "source": [
    "In this section we are going to evaluate the performance of each model by looking at their classification reports and F1-scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a5202999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      1.00      1.00       618\n",
      "         eng       1.00      1.00      1.00       608\n",
      "         nbl       0.99      0.99      0.99       607\n",
      "         nso       1.00      1.00      1.00       603\n",
      "         sot       1.00      1.00      1.00       611\n",
      "         ssw       1.00      1.00      1.00       613\n",
      "         tsn       1.00      1.00      1.00       611\n",
      "         tso       1.00      1.00      1.00       588\n",
      "         ven       1.00      1.00      1.00       604\n",
      "         xho       0.99      1.00      1.00       576\n",
      "         zul       0.98      0.98      0.98       561\n",
      "\n",
      "    accuracy                           1.00      6600\n",
      "   macro avg       1.00      1.00      1.00      6600\n",
      "weighted avg       1.00      1.00      1.00      6600\n",
      "\n",
      "            ------------------------------\n",
      "Random Forest Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      1.00      1.00       618\n",
      "         eng       0.99      1.00      1.00       608\n",
      "         nbl       0.99      0.96      0.97       607\n",
      "         nso       1.00      1.00      1.00       603\n",
      "         sot       1.00      1.00      1.00       611\n",
      "         ssw       0.99      0.98      0.98       613\n",
      "         tsn       1.00      1.00      1.00       611\n",
      "         tso       1.00      1.00      1.00       588\n",
      "         ven       1.00      1.00      1.00       604\n",
      "         xho       0.97      0.99      0.98       576\n",
      "         zul       0.95      0.97      0.96       561\n",
      "\n",
      "    accuracy                           0.99      6600\n",
      "   macro avg       0.99      0.99      0.99      6600\n",
      "weighted avg       0.99      0.99      0.99      6600\n",
      "\n",
      "            ------------------------------\n",
      "Support Vector Machine Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      1.00      1.00       618\n",
      "         eng       1.00      1.00      1.00       608\n",
      "         nbl       0.99      0.99      0.99       607\n",
      "         nso       1.00      1.00      1.00       603\n",
      "         sot       1.00      1.00      1.00       611\n",
      "         ssw       1.00      1.00      1.00       613\n",
      "         tsn       1.00      1.00      1.00       611\n",
      "         tso       1.00      1.00      1.00       588\n",
      "         ven       1.00      1.00      1.00       604\n",
      "         xho       0.99      1.00      1.00       576\n",
      "         zul       0.99      0.99      0.99       561\n",
      "\n",
      "    accuracy                           1.00      6600\n",
      "   macro avg       1.00      1.00      1.00      6600\n",
      "weighted avg       1.00      1.00      1.00      6600\n",
      "\n",
      "            ------------------------------\n",
      "Naive Bayes Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      1.00      1.00       618\n",
      "         eng       0.99      1.00      1.00       608\n",
      "         nbl       1.00      0.99      1.00       607\n",
      "         nso       1.00      1.00      1.00       603\n",
      "         sot       1.00      1.00      1.00       611\n",
      "         ssw       1.00      1.00      1.00       613\n",
      "         tsn       1.00      1.00      1.00       611\n",
      "         tso       1.00      1.00      1.00       588\n",
      "         ven       1.00      1.00      1.00       604\n",
      "         xho       1.00      1.00      1.00       576\n",
      "         zul       1.00      1.00      1.00       561\n",
      "\n",
      "    accuracy                           1.00      6600\n",
      "   macro avg       1.00      1.00      1.00      6600\n",
      "weighted avg       1.00      1.00      1.00      6600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression Classification Report')\n",
    "print(classification_report(y_test, pred_log))\n",
    "print('            ------------------------------')\n",
    "print('Random Forest Classification Report')\n",
    "print(classification_report(y_test, pred_forest))\n",
    "print('            ------------------------------')\n",
    "print('Support Vector Machine Classification Report')\n",
    "print(classification_report(y_test, svc_pred))\n",
    "print('            ------------------------------')\n",
    "print('Naive Bayes Classification Report')\n",
    "print(classification_report(y_test, pred_bayes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b79d53a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F1_score of the Logistic Regression model is: 0.9959074413108815\n",
      "The F1_score of the Random Forest model is: 0.9903075048688084\n",
      "The F1_score of the Support Vector Machine model is: 0.9972708843494191\n",
      "The F1_score of the Naive Bayes model is: 0.998939245648597\n"
     ]
    }
   ],
   "source": [
    "# F1_score for the Logistic Regression model\n",
    "F1_log = f1_score(y_test, pred_log, average = 'weighted')\n",
    "print(\"The F1_score of the Logistic Regression model is: {}\".format(F1_log))\n",
    "\n",
    "# F1_score for Random Forest model\n",
    "F1_forest = f1_score(y_test, pred_forest, average = 'weighted')\n",
    "print(\"The F1_score of the Random Forest model is: {}\".format(F1_forest))\n",
    "\n",
    "# F1_score for the Support Vector Machine model\n",
    "F1_SVM = f1_score(y_test, svc_pred, average = 'weighted')\n",
    "print(\"The F1_score of the Support Vector Machine model is: {}\".format(F1_SVM))\n",
    "\n",
    "# F1_score for the Naive Bayes model\n",
    "F1_Bayes = f1_score(y_test, pred_bayes, average = 'weighted')\n",
    "print(\"The F1_score of the Naive Bayes model is: {}\".format(F1_Bayes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a923bdb",
   "metadata": {},
   "source": [
    "From the above set of results, we can safely conclude that the best performing model is the Naive Bayes model. Furthermore, the Naive Bayes took a short period of time to train the model, compared to other models like Logistic Regression which took a significant amount of training time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
